{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import random\n",
    "np.seterr(divide='raise', over='raise', under='raise', invalid='raise')\n",
    "\n",
    "from data import CITIES, BUSINESSES, USERS, REVIEWS, TIPS, CHECKINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratings(city):\n",
    "    reviews = REVIEWS[city]\n",
    "    ratings = pd.DataFrame(reviews, columns=['user_id', 'business_id', 'stars'])\n",
    "    # onthoud de user en business ids die meer dan 9 keer zijn gereviewd\n",
    "    aantal_reviews_user = ratings.groupby('user_id').size()\n",
    "    voldoende_reviews_user = aantal_reviews_user[aantal_reviews_user > 9].index\n",
    "    \n",
    "    # maak een dataframe met alleen de gebruikers die meer dan 9 keer een rating hebben gegeven\n",
    "    ratings = ratings[ratings['user_id'].isin(voldoende_reviews_user)]\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(ratings, user_id, business_id):\n",
    "    \"\"\"Given a userId and movieId, this function returns the corresponding rating.\n",
    "       Should return NaN if no rating exists.\"\"\"\n",
    "    # select the rating where the userId and the businessId match the given Ids\n",
    "    rating = ratings['stars'][(ratings['user_id'] == user_id) & (ratings['business_id'] == business_id)]\n",
    "    \n",
    "    # if the user has not rated the movie, return NaN\n",
    "    if len(rating) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city(user_id):\n",
    "    \"\"\"returned de stad waarin de gebruiker de meeste ratings heeft gegeven aan bedrijven.\"\"\"\n",
    "    ratings_cities = pd.DataFrame(columns=['business_id', 'user_id', 'city'])\n",
    "    for city in CITIES:\n",
    "        reviews = REVIEWS[city]\n",
    "        df = pd.DataFrame(reviews, columns=['business_id', 'user_id'])\n",
    "        df['city'] = city\n",
    "        ratings_cities = ratings_cities.append(df)\n",
    "    ratings_cities = ratings_cities[ratings_cities['user_id'] == user_id]\n",
    "    \n",
    "    # als de gebruiker nog geen ratings heeft gegeven, kies een random city\n",
    "    if ratings_cities.empty:\n",
    "        return random.choice(CITIES)\n",
    "    \n",
    "    ratings_cities = ratings_cities.groupby('city').size().sort_values(ascending=False)\n",
    "    city = ratings_cities.index[0]\n",
    "    \n",
    "    return city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_center_columns(matrix):\n",
    "    \"\"\"de matrix - het gemiddelde van de columns, om bias te verkomen\"\"\"\n",
    "    return matrix - matrix.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(matrix, id1, id2):\n",
    "    \"\"\"\"Compute the cosine similarity between two rows.\"\"\"\n",
    "    # only take the features that have values for both id1 and id2\n",
    "    selected_features = matrix.loc[id1].notna() & matrix.loc[id2].notna()\n",
    "    \n",
    "    # if no matching features, return NaN\n",
    "    if not selected_features.any():\n",
    "        return 0.0\n",
    "    \n",
    "    # get the features from the matrix\n",
    "    features1 = matrix.loc[id1][selected_features]\n",
    "    features2 = matrix.loc[id2][selected_features]\n",
    "    \n",
    "    # if the id is compered with itself, return maximum similarity (1)\n",
    "    if id1 == id2:\n",
    "        return 1\n",
    "    \n",
    "    # calculate the counter and the caller based on the formula\n",
    "    counter = (features1 * features2).sum()\n",
    "    caller = np.sqrt(np.square(features1).sum()) * np.sqrt(np.square(features2).sum())\n",
    "    \n",
    "    # if the caller is 0, return 0\n",
    "    if caller == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # else return the cosine similarity\n",
    "    return counter / caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_similarity_matrix_cosine(matrix):\n",
    "    \"\"\" creates the similarity matrix based on cosine similarity \"\"\"\n",
    "    similarity_matrix = pd.DataFrame(0, index=matrix.index, columns=matrix.index, dtype=float)\n",
    "    \n",
    "    # calculate the cosine similarity for all posible combinations and put in dataframe\n",
    "    ids = matrix.index\n",
    "    for id1 in ids:\n",
    "        for id2 in ids:\n",
    "            similarity = cosine_similarity(matrix, id1, id2)\n",
    "            similarity_matrix[id1][id2] = similarity\n",
    "            \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_neighborhood(similarity_matrix, utility_matrix, target_user, target_business):\n",
    "    \"\"\"selects all items with similarity > 0\"\"\"\n",
    "    # check if target user is in utility matrix\n",
    "    if not target_user in utility_matrix.columns:\n",
    "        return np.nan\n",
    "    \n",
    "    # check if target business is in utility matrix\n",
    "    if not target_business in utility_matrix.index:\n",
    "        return np.nan\n",
    "    \n",
    "    # select the movies the target user has seen\n",
    "    selected_business = list(utility_matrix.index[utility_matrix.loc[:, target_user].notna()])\n",
    "    \n",
    "    # select the movies from selected_films with a similarity bigger than 0\n",
    "    comparable_business = similarity_matrix[target_business][similarity_matrix.index.isin(selected_business)]\n",
    "    comparable_business = comparable_business[comparable_business > 0]\n",
    "    return comparable_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(neighborhood, utility_matrix, user_id):\n",
    "    \"\"\"\"Compute the weighted mean of the selected movies.\"\"\"\n",
    "    # if the movie has no neighbors, return NaN\n",
    "    if neighborhood is np.nan:\n",
    "        return np.nan\n",
    "    \n",
    "    # calculate the counter and the caller given the formula\n",
    "    business_ids = list(neighborhood.index)\n",
    "    ratings = utility_matrix[user_id][utility_matrix.index.isin(business_ids)]\n",
    "    counter = (neighborhood * ratings).sum()\n",
    "    caller = neighborhood.sum()\n",
    "    \n",
    "    # if the caller is 0, return 0\n",
    "    if caller == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # else return the weighted mean\n",
    "    return counter / caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,d = 0.8):\n",
    "    \"\"\" split data in a training and test set \n",
    "       `d` is the fraction of data in the training set\"\"\"\n",
    "    np.random.seed(seed=5)\n",
    "    mask_test = np.random.rand(data.shape[0]) < d\n",
    "    return data[mask_test], data[~mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_ratings(ratings):\n",
    "    \"\"\" count the number of ratings of a dataset \"\"\"\n",
    "    return ratings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(predicted_ratings):\n",
    "    # calculate based on the rating and the predicted rating the mse using the given formula\n",
    "    diff = predicted_ratings['stars'] - predicted_ratings['predicted_rating']\n",
    "    return (diff**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_user(ratings):\n",
    "    \"\"\" takes a rating table as input and computes the utility matrix of user based \"\"\"\n",
    "    # get business and user id's\n",
    "    business_ids = ratings['business_id'].unique()\n",
    "    user_ids = ratings['user_id'].unique()\n",
    "\n",
    "    # create empty data frame\n",
    "    pivot_data = pd.DataFrame(np.nan, columns=business_ids, index=user_ids, dtype=float)\n",
    "    \n",
    "    for index, row in ratings.iterrows():\n",
    "        pivot_data[row['business_id']][row['user_id']] = row['stars']\n",
    "        \n",
    "    \n",
    "    return pivot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_user_based(similarity, utility, test_data):\n",
    "    # make a copy of the test data\n",
    "    copy_test_data = test_data.copy()\n",
    "    \n",
    "    # iterrate over the rows of the test data to calculate the predicted data for every row in the test data\n",
    "    for x, y in copy_test_data.iterrows():\n",
    "        # use the made functions item based\n",
    "        neighborhood = select_neighborhood(similarity, utility, y['business_id'], y['user_id'])\n",
    "        predicted_rating = weighted_mean(neighborhood, utility, y['business_id'])\n",
    "        copy_test_data.loc[x, 'predicted_rating'] = predicted_rating\n",
    "    return copy_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_item_based(similarity, utility, test_data):\n",
    "    # make a copy of the test data\n",
    "    copy_test_data = test_data.copy()\n",
    "    \n",
    "    # iterrate over the rows of the test data to calculate the predicted data for every row in the test data\n",
    "    for x, y in copy_test_data.iterrows():\n",
    "        # use the made functions item based\n",
    "        neighborhood = select_neighborhood(similarity, utility, y['user_id'], y['business_id'])\n",
    "        predicted_rating = weighted_mean(neighborhood, utility, y['user_id'])\n",
    "        copy_test_data.loc[x, 'predicted_rating'] = predicted_rating\n",
    "    return copy_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_businesses_categorie(city):\n",
    "    \"\"\"Maakt dataframe met alle bedrijven in de stad en de bijbehorende categoriÃ«n.\"\"\"\n",
    "    reviews = BUSINESSES[city]\n",
    "    business_categories = pd.DataFrame(reviews, columns=['business_id', 'categories'])\n",
    "    return business_categories.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_categories(businesses):\n",
    "    \"\"\"Create an unfolded genre dataframe. Unpacks genres seprated by a ',' into seperate rows.\n",
    "\n",
    "    Arguments:\n",
    "    businesses -- a dataFrame containing at least the columns 'business_id' and 'categories' \n",
    "              where genres are seprated by ','\n",
    "    \"\"\"\n",
    "    categories_m = businesses.apply(lambda row: pd.Series([row['business_id']] + row['categories'].lower().split(\",\")), axis=1)\n",
    "    stack_categories = categories_m.set_index(0).stack()\n",
    "    df_stack_categories = stack_categories.to_frame()\n",
    "    df_stack_categories['business_id'] = stack_categories.index.droplevel(1)\n",
    "    df_stack_categories.columns = ['categories', 'business_id']\n",
    "    return df_stack_categories.reset_index()[['business_id', 'categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_categories(df):\n",
    "    \"\"\"Create a one-hot encoded matrix for categories.\n",
    "    \n",
    "    Arguments:\n",
    "    df -- a dataFrame containing at least the columns 'business_id' and 'categories'\n",
    "    \n",
    "    Output:\n",
    "    a matrix containing '0' or '1' in each cell.\n",
    "    1: the movie has the genre\n",
    "    0: the movie does not have the genre\n",
    "    \"\"\"\n",
    "    return df.pivot_table(index = 'business_id', columns = 'categories', aggfunc = 'size', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_similarity_matrix_categories(matrix):\n",
    "    \"\"\"Create a similarity matrix for the categories.\"\"\"\n",
    "    npu = matrix.values\n",
    "    m1 = npu @ npu.T\n",
    "    diag = np.diag(m1)\n",
    "    m2 = m1 / diag\n",
    "    m3 = np.minimum(m2, m2.T)\n",
    "    return pd.DataFrame(m3, index = matrix.index, columns = matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ids(similarity, utility, userId, itemId):\n",
    "    # select right series from matrices and compute\n",
    "    if userId in utility.columns and itemId in similarity.index:\n",
    "        return predict_vectors(utility.loc[:,userId], similarity[itemId])\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_vectors(user_ratings, similarities):\n",
    "    # select only movies actually rated by user\n",
    "    relevant_ratings = user_ratings.dropna()\n",
    "    \n",
    "    # select corresponding similairties\n",
    "    similarities_s = similarities[relevant_ratings.index]\n",
    "    \n",
    "    # select neighborhood\n",
    "    similarities_s = similarities_s[similarities_s > 0.0]\n",
    "    relevant_ratings = relevant_ratings[similarities_s.index]\n",
    "    \n",
    "    # if there's nothing left return a prediction of 0\n",
    "    norm = similarities_s.sum()\n",
    "    if(norm == 0):\n",
    "        return 0\n",
    "    \n",
    "    # compute a weighted average (i.e. neighborhood is all) \n",
    "    return np.dot(relevant_ratings, similarities_s)/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_content(similarity, utility, to_predict):\n",
    "    \"\"\"Predicts the predicted rating for the input test data.\n",
    "    \n",
    "    Arguments:\n",
    "    similarity -- a dataFrame that describes the similarity between items\n",
    "    utility    -- a dataFrame that contains a rating for each user (columns) and each movie (rows). \n",
    "                  If a user did not rate an item the value np.nan is assumed. \n",
    "    to_predict -- A dataFrame containing at least the columns movieId and userId for which to do the predictions\n",
    "    \"\"\"\n",
    "    # copy input (don't overwrite)\n",
    "    ratings_test_c = to_predict.copy()\n",
    "    # apply prediction to each row\n",
    "    ratings_test_c['predicted_rating'] = to_predict.apply(lambda row: predict_ids(similarity, utility, row['user_id'], row['business_id']), axis=1)\n",
    "    return ratings_test_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uitvoeren recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityname = 'ajax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits de data in training en test set\n",
    "ratings = ratings(city=cityname)\n",
    "ratings, ratings_test = split_data(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_user = utility_user(ratings)\n",
    "centered_utility_user = mean_center_columns(utility_user)\n",
    "similarity_user = create_similarity_matrix_cosine(centered_utility_user)\n",
    "predicted_user_based = predict_ratings_user_based(similarity_user, utility_user, ratings_test).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(predicted_user_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_item = utility_user.T\n",
    "centered_utility_item = mean_center_columns(utility_item)\n",
    "similarity_item = create_similarity_matrix_cosine(centered_utility_item)\n",
    "predicted_item_based = predict_ratings_item_based(similarity_item, utility_item, ratings_test).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(predicted_item_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses = df_businesses_categorie(cityname)\n",
    "df_categories = extract_categories(businesses)\n",
    "utility_content = pivot_categories(df_categories)\n",
    "similarity_content = create_similarity_matrix_categories(utility_content)\n",
    "predicted_ratings_content = predict_ratings_content(similarity_content, utility_item, ratings_test)\n",
    "predicted_ratings_content = predicted_ratings_content[predicted_ratings_content['predicted_rating'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(predicted_ratings_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gecombineerd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_test['predicted_rating'] = ((predicted_ratings_content['predicted_rating'] + predicted_item_based['predicted_rating'] + predicted_user_based['predicted_rating']) / 3)\n",
    "ratings_test = ratings_test.dropna()\n",
    "mse(ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_test['predicted_rating'] = ((predicted_ratings_content['predicted_rating'] + predicted_item_based['predicted_rating']) / 2)\n",
    "ratings_test = ratings_test.dropna()\n",
    "mse(ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_test['predicted_rating'] = ((predicted_ratings_content['predicted_rating'] + predicted_user_based['predicted_rating']) / 2)\n",
    "ratings_test = ratings_test.dropna()\n",
    "mse(ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_test['predicted_rating'] = ((predicted_item_based['predicted_rating'] + predicted_user_based['predicted_rating']) / 2)\n",
    "ratings_test = ratings_test.dropna()\n",
    "mse(ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the mean rating of the trainingset as the predicted rating and calculate the mse of it\n",
    "mean_ratings = ratings['stars'].mean()\n",
    "ratings_test_e = ratings_test[['user_id', 'business_id', 'stars']].copy()\n",
    "ratings_test_e['predicted_rating'] = [mean_ratings for index in ratings_test_e.index]\n",
    "mse(ratings_test_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend functie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id=None, business_id=None, city=None, n=10):\n",
    "    \"\"\"\n",
    "    Returns n recommendations as a list of dicts.\n",
    "    Optionally takes in a user_id, business_id and/or city.\n",
    "    A recommendation is a dictionary in the form of:\n",
    "        {\n",
    "            business_id:str\n",
    "            stars:str\n",
    "            name:str\n",
    "            city:str\n",
    "            adress:str\n",
    "        }\n",
    "    \"\"\"\n",
    "    if not city:\n",
    "        # selecteer alle steden waar een gebruiker een bedrijf gereviewd heeft\n",
    "        city = get_city(user_id)\n",
    "        \n",
    "    ratings_ = ratings(city)\n",
    "    \n",
    "    # user based\n",
    "    utility_user_ = utility_user(ratings_)\n",
    "    centered_utility_user_ = mean_center_columns(utility_user_)\n",
    "    similarity_user_ = create_similarity_matrix_cosine(centered_utility_user_)\n",
    "\n",
    "    # item based\n",
    "    utility_item_ = utility_user_.T\n",
    "    centered_utility_item_ = mean_center_columns(utility_item_)\n",
    "    similarity_item_ = create_similarity_matrix_cosine(centered_utility_item_)\n",
    "\n",
    "    # conent based\n",
    "    businesses_ = df_businesses_categorie(city)\n",
    "    df_categories_ = extract_categories(businesses_)\n",
    "    utility_content_ = pivot_categories(df_categories_)\n",
    "    similarity_content_ = create_similarity_matrix_categories(utility_content_)\n",
    "    \n",
    "    # create DataFrame with the user and all cities you want the predicted rating from\n",
    "    df_ratings_user = pd.DataFrame(BUSINESSES[city], columns=['business_id'])\n",
    "    df_ratings_user['user_id'] = user_id\n",
    "    \n",
    "    predicted_user = predict_ratings_user_based(similarity_user_, utility_user_, df_ratings_user).dropna()\n",
    "    predicted_item = predict_ratings_item_based(similarity_item_, utility_item_, df_ratings_user).dropna()\n",
    "    predicted_content = predict_ratings_content(similarity_content_, utility_item_, df_ratings_user)\n",
    "    predicted_content = predicted_content[predicted_content['predicted_rating'] > 0]\n",
    "\n",
    "    df_ratings_user['predicted_rating'] = ((predicted_item['predicted_rating'] + predicted_user['predicted_rating'] + predicted_content['predicted_rating']) / 3)\n",
    "\n",
    "    df_ratings_user = df_ratings_user.dropna().sort_values(by='predicted_rating', ascending=False)\n",
    "    \n",
    "    return df_ratings_user[:10]\n",
    "\n",
    "recommend(user_id='DRlIsW15Zn2qwYdOuhHlsg', city='westlake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>lvMDy7xL-hpkLUpRJUnJwQ</td>\n",
       "      <td>7LCG3o2KW2jgKgbKN0DQOg</td>\n",
       "      <td>4.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>hSporfb8IjTQaw_9ytHrFw</td>\n",
       "      <td>7LCG3o2KW2jgKgbKN0DQOg</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gQNeEQVB5aBmQM-K2aBxBQ</td>\n",
       "      <td>7LCG3o2KW2jgKgbKN0DQOg</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>oUS-cKFK8ffdzyf4HplXpQ</td>\n",
       "      <td>7LCG3o2KW2jgKgbKN0DQOg</td>\n",
       "      <td>4.052218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>-tSTLaafhkQ7iB5Bl5zgPg</td>\n",
       "      <td>7LCG3o2KW2jgKgbKN0DQOg</td>\n",
       "      <td>4.039903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Uyvu1gvRreo2e-p9T3HHxQ</td>\n",
       "      <td>7LCG3o2KW2jgKgbKN0DQOg</td>\n",
       "      <td>4.024602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>X1RLcu527EkR6lDMffI2LA</td>\n",
       "      <td>7LCG3o2KW2jgKgbKN0DQOg</td>\n",
       "      <td>4.020202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>KDpgTDtgqUqrFmUTrCWUtA</td>\n",
       "      <td>7LCG3o2KW2jgKgbKN0DQOg</td>\n",
       "      <td>4.009012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>MRjbo3l3kY_AL4NlVIiZGg</td>\n",
       "      <td>7LCG3o2KW2jgKgbKN0DQOg</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Qw45ZqhBR0VI5_cI60SgeQ</td>\n",
       "      <td>7LCG3o2KW2jgKgbKN0DQOg</td>\n",
       "      <td>3.970131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                business_id                 user_id  predicted_rating\n",
       "107  lvMDy7xL-hpkLUpRJUnJwQ  7LCG3o2KW2jgKgbKN0DQOg          4.757576\n",
       "77   hSporfb8IjTQaw_9ytHrFw  7LCG3o2KW2jgKgbKN0DQOg          4.333333\n",
       "5    gQNeEQVB5aBmQM-K2aBxBQ  7LCG3o2KW2jgKgbKN0DQOg          4.166667\n",
       "66   oUS-cKFK8ffdzyf4HplXpQ  7LCG3o2KW2jgKgbKN0DQOg          4.052218\n",
       "403  -tSTLaafhkQ7iB5Bl5zgPg  7LCG3o2KW2jgKgbKN0DQOg          4.039903\n",
       "29   Uyvu1gvRreo2e-p9T3HHxQ  7LCG3o2KW2jgKgbKN0DQOg          4.024602\n",
       "41   X1RLcu527EkR6lDMffI2LA  7LCG3o2KW2jgKgbKN0DQOg          4.020202\n",
       "73   KDpgTDtgqUqrFmUTrCWUtA  7LCG3o2KW2jgKgbKN0DQOg          4.009012\n",
       "170  MRjbo3l3kY_AL4NlVIiZGg  7LCG3o2KW2jgKgbKN0DQOg          4.000000\n",
       "302  Qw45ZqhBR0VI5_cI60SgeQ  7LCG3o2KW2jgKgbKN0DQOg          3.970131"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(user_id='7LCG3o2KW2jgKgbKN0DQOg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
